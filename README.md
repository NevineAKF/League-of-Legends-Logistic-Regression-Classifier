# League of Legends Match Outcome Prediction (Logistic Regression, PyTorch)

## Overview
A compact, production-minded pipeline for predicting League of Legends match outcomes (win/loss) using a logistic regression model in PyTorch. 
The project emphasizes clean preprocessing, stable training, explicit regularization (L2), robust evaluation (confusion matrix, classification report, ROC/AUC), 
model persistence, and small-scale hyperparameter tuning.

This repository contains a polished notebook and reproducible code to:
- Load and preprocess match-level data
- Train a logistic regression classifier
- Regularize with L2 (weight decay)
- Evaluate with confusion matrix, classification report, and ROC/AUC
- Save & reload the trained model
- Tune the learning rate
- Inspect feature importance via learned weights

## Data
- **File**: `league_of_legends_data_large.csv`
- **Target**: `win` (0 = loss, 1 = win)
- **Features**: numeric in-game statistics (kills, deaths, assists, gold, towers, dragons, barons, etc.).
- **Note**: The pipeline standardizes features (mean 0, std 1) and leaves the target untouched.

## Environment
- Python 3.10+
- PyTorch, pandas, scikit-learn, matplotlib

Install (if needed):
```bash
pip install torch pandas scikit-learn matplotlib
```

## Project Structure
- `League_of_Legends_Win_Prediction_Pro.ipynb` — production-style notebook (clean sections, minimal didactic text)
- `league_of_legends_data_large.csv` — dataset (not included; add locally)
- `confusion_matrix.png` / `roc_curve.png` — evaluation artifacts (optional)
- `logistic_regression_model.pth` — saved model (optional, generated by notebook)

## Methodology
### Data Pipeline
1. Load CSV into pandas
2. Split X (features) and y (`win`)
3. Train/test split (80/20, stratified)
4. Standardize features with `StandardScaler` (fit on train, transform train/test)
5. Convert to PyTorch tensors

### Model
- Logistic regression (`nn.Linear(input_dim, 1)` + `Sigmoid`)
- Loss: Binary Cross-Entropy (`nn.BCELoss`)
- Optimizer: SGD

### Training
- Baseline training for 1000 epochs
- Print loss every 100 epochs

### Regularization
- L2 via `weight_decay` in SGD (ridge-style)
- Retrain 1000 epochs and compare

### Evaluation
- Accuracy on train/test
- Confusion matrix, classification report
- ROC curve + AUC

### Persistence
- Save weights via `model.state_dict()`
- Reload into a fresh instance; verify identical predictions/accuracy

### Hyperparameter Tuning
- Grid over learning rates: `[0.01, 0.05, 0.1]`
- 100-epoch runs per LR; pick best on test accuracy

### Feature Importance
- Extract linear weights
- Rank by absolute magnitude
- Visualize top features

## Results
### Step 3 — Baseline (no L2)
- Training Accuracy: **52.13%**
- Testing Accuracy:  **53.50%**

### Step 4 — L2 Regularization
- Training Accuracy: **52.50%**
- Testing Accuracy:  **56.00%**

### Step 5 — Classification Report (Test Set)
```
precision    recall  f1-score   support

        Loss       0.53      0.49      0.51        98
         Win       0.54      0.58      0.56       102

    accuracy                           0.54       200
   macro avg       0.53      0.53      0.53       200
weighted avg       0.53      0.54      0.53       200
```
_Confusion Matrix_ and _ROC Curve_ are generated by the notebook:
- Confusion Matrix: `confusion_matrix.png`
- ROC Curve: `roc_curve.png`

### Step 7 — Learning Rate Tuning
- Tested LRs: `[0.01, 0.05, 0.1]`
- Best LR: **0.1** with Test Accuracy **58.00%**

> Overall: L2 regularization provided a mild lift over baseline. A higher learning rate improved test accuracy within the logistic regression regime.

## How to Run
1. Place `league_of_legends_data_large.csv` alongside the notebook.
2. Open `League_of_Legends_Win_Prediction_Pro.ipynb` and run all cells.
3. Optional: export figures and model artifacts for the README.

## Notes & Future Work
- Logistic regression is intentionally simple; consider tree ensembles or small neural nets for potentially higher accuracy.
- Investigate class imbalance and alternative classification thresholds (from ROC) for better F1/Recall.
- Add cross-validation and regularization sweeps (grid/random) for stronger selection.

---

"This project was developed as part of the IBM AI Engineering course. The code is shared for educational purposes only and is not licensed for commercial use."
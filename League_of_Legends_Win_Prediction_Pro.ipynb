{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d28ae3e3",
   "metadata": {},
   "source": [
    "# League of Legends — Win Prediction (Logistic Regression, PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0936285",
   "metadata": {},
   "source": [
    "**Sections**\n",
    "- Data Loading & Preprocessing\n",
    "- Model Definition\n",
    "- Training\n",
    "- Regularization (L2)\n",
    "- Evaluation & Visualization\n",
    "- Model Persistence\n",
    "- Hyperparameter Tuning\n",
    "- Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193cdac",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" height=300 width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eac9e6",
   "metadata": {},
   "source": [
    "# Final Project: League of Legends Match Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install torch\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80340d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60251a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"/\"):\n",
    "    for file in files:\n",
    "        if file == \"league_of_legends_data_large.csv\":\n",
    "            print(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea137de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\".\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d1d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"league_of_legends_data_large.csv\")\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc661930",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"win\"]).to_numpy(dtype=np.float32)\n",
    "y = data[\"win\"].to_numpy(dtype=np.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f760f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158b13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
    "y_test_t  = torch.tensor(y_test,  dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9aead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Task 2 — Model Definition:\n",
    "    - Define a Logistic Regression model class inheriting from nn.Module\n",
    "    - Implement a single Linear layer with a Sigmoid activation to output probabilities\n",
    "    - Initialize the model, Binary Cross-Entropy loss function, and SGD optimizer\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "input_dim = X_train.shape[1] \n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()  \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "\n",
    "model = LogisticRegressionModel(input_dim)\n",
    "criterion = nn.BCELoss()                    # Binary Cross-Entropy\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Step 3: Train the logistic regression model =====\n",
    "\n",
    "# init\n",
    "model = LogisticRegressionModel(input_dim)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# train\n",
    "epochs = 1000\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_t)\n",
    "    loss = criterion(outputs, y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:4d} | Loss: {loss.item():.6f}\")\n",
    "\n",
    "# evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_preds = (model(X_train_t) >= 0.5).float()\n",
    "    test_preds  = (model(X_test_t)  >= 0.5).float()\n",
    "    train_acc = (train_preds.eq(y_train_t).sum() / y_train_t.shape[0]).item()\n",
    "    test_acc  = (test_preds.eq(y_test_t).sum()  / y_test_t.shape[0]).item()\n",
    "\n",
    "print(f\"\\nTraining Accuracy: {train_acc*100:.2f}%\")\n",
    "print(f\"Testing  Accuracy: {test_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Optimization (L2) + Evaluation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model_l2 = LogisticRegressionModel(input_dim)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_l2 = optim.SGD(model_l2.parameters(), lr=0.01, weight_decay=0.01)\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model_l2.train()\n",
    "    optimizer_l2.zero_grad()\n",
    "    outputs = model_l2(X_train_t)\n",
    "    loss = criterion(outputs, y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer_l2.step()\n",
    "    if epoch % 100 == 0 or epoch == 1:\n",
    "        print(f\"[L2] Epoch {epoch:4d} | Loss: {loss.item():.6f}\")\n",
    "\n",
    "model_l2.eval()\n",
    "with torch.no_grad():\n",
    "    train_preds_l2 = (model_l2(X_train_t) >= 0.5).float()\n",
    "    test_preds_l2  = (model_l2(X_test_t)  >= 0.5).float()\n",
    "    train_acc_l2 = (train_preds_l2.eq(y_train_t).sum() / y_train_t.shape[0]).item()\n",
    "    test_acc_l2  = (test_preds_l2.eq(y_test_t).sum()  / y_test_t.shape[0]).item()\n",
    "\n",
    "print(f\"\\n[L2] Training Accuracy: {train_acc_l2*100:.2f}%\")\n",
    "print(f\"[L2] Testing  Accuracy: {test_acc_l2*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8579fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import itertools\n",
    "\n",
    "# Retrain the model with L2 regularization\n",
    "model = LogisticRegressionModel(input_dim)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_t)\n",
    "    loss = criterion(outputs, y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"[L2] Epoch {epoch:4d} | Loss: {loss.item():.6f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_test_t)\n",
    "    y_pred_test_labels = (y_pred_test > 0.5).float()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test_labels)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = range(2)\n",
    "plt.xticks(tick_marks, ['Loss', 'Win'], rotation=45)\n",
    "plt.yticks(tick_marks, ['Loss', 'Win'])\n",
    "\n",
    "thresh = cm.max() / 2\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j],\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_test_labels, target_names=['Loss', 'Win']))\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f968ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Model Saving and Loading\n",
    "\n",
    "# Save the trained model parameters\n",
    "torch.save(model.state_dict(), 'logistic_regression_model.pth')\n",
    "\n",
    "# Create a new model instance\n",
    "loaded_model = LogisticRegressionModel(input_dim)\n",
    "\n",
    "# Load the saved state dictionary into the new model\n",
    "loaded_model.load_state_dict(torch.load('logistic_regression_model.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "# Evaluate the loaded model on the test dataset\n",
    "with torch.no_grad():\n",
    "    y_pred_test_loaded = loaded_model(X_test_t)\n",
    "    y_pred_test_labels_loaded = (y_pred_test_loaded > 0.5).float()\n",
    "    accuracy_loaded = (y_pred_test_labels_loaded.eq(y_test_t).sum().item()) / y_test_t.shape[0]\n",
    "\n",
    "print(f\"Loaded Model Test Accuracy: {accuracy_loaded * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Hyperparameter Tuning (learning rate)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "lrs = [0.01, 0.05, 0.1]\n",
    "results = []\n",
    "\n",
    "def acc_from_probs(probs, y_true, thr=0.5):\n",
    "    preds = (probs >= thr).float()\n",
    "    return (preds.eq(y_true).sum().item()) / y_true.shape[0]\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for lr in lrs:\n",
    "    # Reinitialize model and optimizer for each LR\n",
    "    model_tune = LogisticRegressionModel(input_dim)\n",
    "    criterion_tune = nn.BCELoss()\n",
    "    optimizer_tune = optim.SGD(model_tune.parameters(), lr=lr)\n",
    "\n",
    "    # Train\n",
    "    for _ in range(epochs):\n",
    "        model_tune.train()\n",
    "        optimizer_tune.zero_grad()\n",
    "        out = model_tune(X_train_t)\n",
    "        loss = criterion_tune(out, y_train_t)\n",
    "        loss.backward()\n",
    "        optimizer_tune.step()\n",
    "\n",
    "    # Evaluate on test\n",
    "    model_tune.eval()\n",
    "    with torch.no_grad():\n",
    "        test_probs = model_tune(X_test_t)\n",
    "        test_acc = acc_from_probs(test_probs, y_test_t, thr=0.5)\n",
    "\n",
    "    results.append((lr, test_acc))\n",
    "    print(f\"LR={lr} -> Test Accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Pick best\n",
    "best_lr, best_acc = sorted(results, key=lambda x: x[1], reverse=True)[0]\n",
    "print(f\"\\nBest LR: {best_lr} with Test Accuracy: {best_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e2e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Feature Importance\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Extract weights from the linear layer\n",
    "weights = model.linear.weight.detach().cpu().numpy().flatten()\n",
    "\n",
    "# 2) Feature names (align with your dataset)\n",
    "features = data.drop(columns=[\"win\"]).columns\n",
    "\n",
    "# 3) Build a DataFrame and sort by absolute importance\n",
    "fi = pd.DataFrame({\n",
    "    \"Feature\": features,\n",
    "    \"Weight\": weights,\n",
    "    \"Importance\": np.abs(weights)\n",
    "}).sort_values(\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(fi.head(10))  # top features\n",
    "\n",
    "# 4) Plot (top-k for readability)\n",
    "top_k = min(20, len(fi))\n",
    "plt.figure(figsize=(10, max(4, top_k*0.35)))\n",
    "plt.barh(fi[\"Feature\"].iloc[:top_k][::-1], fi[\"Importance\"].iloc[:top_k][::-1])\n",
    "plt.xlabel(\"Absolute Weight (Importance)\")\n",
    "plt.title(\"Top Feature Importances — Logistic Regression\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc5fbc1",
   "metadata": {},
   "source": [
    "#### Conclusion:  \n",
    "\n",
    "Congratulations on completing the project! In this final project, you built a logistic regression model to predict the outcomes of League of Legends matches based on various in-game statistics. This comprehensive project involved several key steps, including data loading and preprocessing, model implementation, training, optimization, evaluation, visualization, model saving and loading, hyperparameter tuning, and feature importance analysis. This project provided hands-on experience with the complete workflow of developing a machine learning model for binary classification tasks using PyTorch.\n",
    "\n",
    "© Copyright IBM Corporation. All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0d71ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
